{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>number</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>elongation</th>\n",
       "      <th>solidity</th>\n",
       "      <th>convexity</th>\n",
       "      <th>iso_factor</th>\n",
       "      <th>depth</th>\n",
       "      <th>lobedness</th>\n",
       "      <th>intensity</th>\n",
       "      <th>contrast</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>third_moment</th>\n",
       "      <th>uniformity</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72694</td>\n",
       "      <td>1.4742</td>\n",
       "      <td>0.32396</td>\n",
       "      <td>0.98535</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.835920</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.047790</td>\n",
       "      <td>0.127950</td>\n",
       "      <td>0.016108</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>1.17560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.74173</td>\n",
       "      <td>1.5257</td>\n",
       "      <td>0.36116</td>\n",
       "      <td>0.98152</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.798670</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.024160</td>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.008119</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.69659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.76722</td>\n",
       "      <td>1.5725</td>\n",
       "      <td>0.38998</td>\n",
       "      <td>0.97755</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.808120</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>0.010121</td>\n",
       "      <td>0.011897</td>\n",
       "      <td>0.057445</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.44348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.73797</td>\n",
       "      <td>1.4597</td>\n",
       "      <td>0.35376</td>\n",
       "      <td>0.97566</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.816970</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.008607</td>\n",
       "      <td>0.015950</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.58785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.82301</td>\n",
       "      <td>1.7707</td>\n",
       "      <td>0.44462</td>\n",
       "      <td>0.97698</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.754930</td>\n",
       "      <td>0.007428</td>\n",
       "      <td>0.010042</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.045339</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.34214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.72997</td>\n",
       "      <td>1.4892</td>\n",
       "      <td>0.34284</td>\n",
       "      <td>0.98755</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.844820</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.010487</td>\n",
       "      <td>0.058528</td>\n",
       "      <td>0.003414</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.34068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.82063</td>\n",
       "      <td>1.7529</td>\n",
       "      <td>0.44458</td>\n",
       "      <td>0.97964</td>\n",
       "      <td>0.99649</td>\n",
       "      <td>0.767700</td>\n",
       "      <td>0.005928</td>\n",
       "      <td>0.006395</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>0.080587</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.53904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.77982</td>\n",
       "      <td>1.6215</td>\n",
       "      <td>0.39222</td>\n",
       "      <td>0.98512</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.808160</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>0.024875</td>\n",
       "      <td>0.089686</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.66975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.83089</td>\n",
       "      <td>1.8199</td>\n",
       "      <td>0.45693</td>\n",
       "      <td>0.98240</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.771060</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.006564</td>\n",
       "      <td>0.007245</td>\n",
       "      <td>0.040616</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.33696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.90631</td>\n",
       "      <td>2.3906</td>\n",
       "      <td>0.58336</td>\n",
       "      <td>0.97683</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.664190</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>0.012848</td>\n",
       "      <td>0.007010</td>\n",
       "      <td>0.042347</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.28082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.74590</td>\n",
       "      <td>1.4927</td>\n",
       "      <td>0.34116</td>\n",
       "      <td>0.98296</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.830880</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>0.005640</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>0.036511</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.25026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.79606</td>\n",
       "      <td>1.6934</td>\n",
       "      <td>0.43387</td>\n",
       "      <td>0.98181</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.769850</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.013677</td>\n",
       "      <td>0.057832</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.49751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93361</td>\n",
       "      <td>2.7582</td>\n",
       "      <td>0.64257</td>\n",
       "      <td>0.98346</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.598510</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.005573</td>\n",
       "      <td>0.029712</td>\n",
       "      <td>0.089889</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.91499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.91186</td>\n",
       "      <td>2.4994</td>\n",
       "      <td>0.60323</td>\n",
       "      <td>0.98300</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.649160</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>0.072486</td>\n",
       "      <td>0.005227</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.67811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.89063</td>\n",
       "      <td>2.2927</td>\n",
       "      <td>0.56667</td>\n",
       "      <td>0.98732</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.664270</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.029272</td>\n",
       "      <td>0.091328</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.87177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.86755</td>\n",
       "      <td>2.0090</td>\n",
       "      <td>0.51464</td>\n",
       "      <td>0.98691</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.702770</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.030348</td>\n",
       "      <td>0.092063</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.94545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.91852</td>\n",
       "      <td>2.5247</td>\n",
       "      <td>0.61648</td>\n",
       "      <td>0.97870</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.630370</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.023090</td>\n",
       "      <td>0.082029</td>\n",
       "      <td>0.006684</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.71713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.88795</td>\n",
       "      <td>2.2038</td>\n",
       "      <td>0.56218</td>\n",
       "      <td>0.97835</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.641580</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.006387</td>\n",
       "      <td>0.032722</td>\n",
       "      <td>0.092969</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>1.00800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.85121</td>\n",
       "      <td>1.9548</td>\n",
       "      <td>0.48920</td>\n",
       "      <td>0.98622</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.702670</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.020258</td>\n",
       "      <td>0.070841</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.74174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.89084</td>\n",
       "      <td>2.2979</td>\n",
       "      <td>0.57815</td>\n",
       "      <td>0.97389</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.645980</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>0.042443</td>\n",
       "      <td>0.028461</td>\n",
       "      <td>0.086477</td>\n",
       "      <td>0.007423</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.91307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.93062</td>\n",
       "      <td>2.8973</td>\n",
       "      <td>0.65828</td>\n",
       "      <td>0.98182</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.579500</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>0.023606</td>\n",
       "      <td>0.072237</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.90513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.84113</td>\n",
       "      <td>1.8600</td>\n",
       "      <td>0.46549</td>\n",
       "      <td>0.99039</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.759760</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.132340</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.004453</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>1.65300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70273</td>\n",
       "      <td>1.2099</td>\n",
       "      <td>0.36317</td>\n",
       "      <td>0.92110</td>\n",
       "      <td>0.98772</td>\n",
       "      <td>0.605550</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>0.101340</td>\n",
       "      <td>0.089301</td>\n",
       "      <td>0.200880</td>\n",
       "      <td>0.038786</td>\n",
       "      <td>0.015895</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>1.53710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.66307</td>\n",
       "      <td>1.2065</td>\n",
       "      <td>0.32559</td>\n",
       "      <td>0.94952</td>\n",
       "      <td>0.99649</td>\n",
       "      <td>0.759540</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.032621</td>\n",
       "      <td>0.021815</td>\n",
       "      <td>0.097143</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.53410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.61289</td>\n",
       "      <td>1.0991</td>\n",
       "      <td>0.33117</td>\n",
       "      <td>0.92405</td>\n",
       "      <td>0.98421</td>\n",
       "      <td>0.616610</td>\n",
       "      <td>0.025545</td>\n",
       "      <td>0.118770</td>\n",
       "      <td>0.054687</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.025145</td>\n",
       "      <td>0.011672</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>1.10760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.70668</td>\n",
       "      <td>1.2510</td>\n",
       "      <td>0.38111</td>\n",
       "      <td>0.94226</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.692500</td>\n",
       "      <td>0.019432</td>\n",
       "      <td>0.068724</td>\n",
       "      <td>0.031587</td>\n",
       "      <td>0.115020</td>\n",
       "      <td>0.013056</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.72247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.66889</td>\n",
       "      <td>1.1435</td>\n",
       "      <td>0.38460</td>\n",
       "      <td>0.90355</td>\n",
       "      <td>0.99649</td>\n",
       "      <td>0.605710</td>\n",
       "      <td>0.028329</td>\n",
       "      <td>0.146060</td>\n",
       "      <td>0.057506</td>\n",
       "      <td>0.159310</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>1.13650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.50139</td>\n",
       "      <td>1.0066</td>\n",
       "      <td>0.29593</td>\n",
       "      <td>0.91585</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.640290</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>0.086347</td>\n",
       "      <td>0.054635</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>0.024899</td>\n",
       "      <td>0.011106</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>1.05110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.60803</td>\n",
       "      <td>1.0646</td>\n",
       "      <td>0.34460</td>\n",
       "      <td>0.90487</td>\n",
       "      <td>0.99649</td>\n",
       "      <td>0.675170</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.185380</td>\n",
       "      <td>0.062450</td>\n",
       "      <td>0.164110</td>\n",
       "      <td>0.026225</td>\n",
       "      <td>0.010602</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>1.23070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.56599</td>\n",
       "      <td>1.0427</td>\n",
       "      <td>0.35318</td>\n",
       "      <td>0.89086</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.620680</td>\n",
       "      <td>0.032971</td>\n",
       "      <td>0.197850</td>\n",
       "      <td>0.026348</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>0.011088</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.62671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99670</td>\n",
       "      <td>11.3610</td>\n",
       "      <td>0.91400</td>\n",
       "      <td>0.91815</td>\n",
       "      <td>0.93684</td>\n",
       "      <td>0.144350</td>\n",
       "      <td>0.019976</td>\n",
       "      <td>0.072629</td>\n",
       "      <td>0.020667</td>\n",
       "      <td>0.085514</td>\n",
       "      <td>0.007259</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.67925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99841</td>\n",
       "      <td>16.8320</td>\n",
       "      <td>0.94116</td>\n",
       "      <td>0.85531</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.094537</td>\n",
       "      <td>0.035845</td>\n",
       "      <td>0.233840</td>\n",
       "      <td>0.012341</td>\n",
       "      <td>0.066682</td>\n",
       "      <td>0.004427</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.41828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99799</td>\n",
       "      <td>15.0680</td>\n",
       "      <td>0.93667</td>\n",
       "      <td>0.88070</td>\n",
       "      <td>0.95789</td>\n",
       "      <td>0.121320</td>\n",
       "      <td>0.032164</td>\n",
       "      <td>0.188280</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>0.054827</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.50576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>10.3770</td>\n",
       "      <td>0.90564</td>\n",
       "      <td>0.92135</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.179410</td>\n",
       "      <td>0.016647</td>\n",
       "      <td>0.050433</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.071662</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.71514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>0.99505</td>\n",
       "      <td>10.7360</td>\n",
       "      <td>0.90851</td>\n",
       "      <td>0.92586</td>\n",
       "      <td>0.99649</td>\n",
       "      <td>0.182360</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.148560</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>0.069610</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.59218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>0.99518</td>\n",
       "      <td>10.4210</td>\n",
       "      <td>0.90385</td>\n",
       "      <td>0.96551</td>\n",
       "      <td>0.98947</td>\n",
       "      <td>0.200510</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.010855</td>\n",
       "      <td>0.021258</td>\n",
       "      <td>0.080385</td>\n",
       "      <td>0.006420</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.66405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>0.99530</td>\n",
       "      <td>10.6300</td>\n",
       "      <td>0.90598</td>\n",
       "      <td>0.88866</td>\n",
       "      <td>0.95789</td>\n",
       "      <td>0.159670</td>\n",
       "      <td>0.025636</td>\n",
       "      <td>0.119610</td>\n",
       "      <td>0.014782</td>\n",
       "      <td>0.065416</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.52178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99515</td>\n",
       "      <td>10.0070</td>\n",
       "      <td>0.90328</td>\n",
       "      <td>0.91594</td>\n",
       "      <td>0.97719</td>\n",
       "      <td>0.162440</td>\n",
       "      <td>0.033129</td>\n",
       "      <td>0.199750</td>\n",
       "      <td>0.017258</td>\n",
       "      <td>0.070646</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.59946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>0.99871</td>\n",
       "      <td>19.0380</td>\n",
       "      <td>0.94834</td>\n",
       "      <td>0.85100</td>\n",
       "      <td>0.90702</td>\n",
       "      <td>0.086183</td>\n",
       "      <td>0.073048</td>\n",
       "      <td>0.971170</td>\n",
       "      <td>0.007817</td>\n",
       "      <td>0.048089</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.34029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91090</td>\n",
       "      <td>2.5488</td>\n",
       "      <td>0.61060</td>\n",
       "      <td>0.97388</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.558180</td>\n",
       "      <td>0.019720</td>\n",
       "      <td>0.070775</td>\n",
       "      <td>0.101320</td>\n",
       "      <td>0.170220</td>\n",
       "      <td>0.028158</td>\n",
       "      <td>0.007461</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>2.38470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0.90391</td>\n",
       "      <td>2.4580</td>\n",
       "      <td>0.59770</td>\n",
       "      <td>0.98610</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.614290</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>0.008173</td>\n",
       "      <td>0.089020</td>\n",
       "      <td>0.167060</td>\n",
       "      <td>0.027151</td>\n",
       "      <td>0.007219</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>1.89370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0.90755</td>\n",
       "      <td>2.5820</td>\n",
       "      <td>0.62394</td>\n",
       "      <td>0.96837</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.556740</td>\n",
       "      <td>0.031714</td>\n",
       "      <td>0.183050</td>\n",
       "      <td>0.079387</td>\n",
       "      <td>0.162130</td>\n",
       "      <td>0.025613</td>\n",
       "      <td>0.007412</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>1.69510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0.91708</td>\n",
       "      <td>2.6498</td>\n",
       "      <td>0.62919</td>\n",
       "      <td>0.98493</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.579260</td>\n",
       "      <td>0.006805</td>\n",
       "      <td>0.008429</td>\n",
       "      <td>0.082187</td>\n",
       "      <td>0.168770</td>\n",
       "      <td>0.027693</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>1.71570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>0.91660</td>\n",
       "      <td>2.6711</td>\n",
       "      <td>0.63330</td>\n",
       "      <td>0.98228</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.516190</td>\n",
       "      <td>0.017465</td>\n",
       "      <td>0.055514</td>\n",
       "      <td>0.103680</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.031721</td>\n",
       "      <td>0.008198</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>1.97300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0.89420</td>\n",
       "      <td>2.4203</td>\n",
       "      <td>0.59323</td>\n",
       "      <td>0.98407</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.607940</td>\n",
       "      <td>0.017430</td>\n",
       "      <td>0.055294</td>\n",
       "      <td>0.101020</td>\n",
       "      <td>0.187480</td>\n",
       "      <td>0.033957</td>\n",
       "      <td>0.009815</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>1.82750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>0.93847</td>\n",
       "      <td>3.0198</td>\n",
       "      <td>0.67312</td>\n",
       "      <td>0.98733</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.532340</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.076290</td>\n",
       "      <td>0.180170</td>\n",
       "      <td>0.031440</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>1.24340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>0.89518</td>\n",
       "      <td>2.3875</td>\n",
       "      <td>0.58100</td>\n",
       "      <td>0.98796</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.638330</td>\n",
       "      <td>0.007793</td>\n",
       "      <td>0.011052</td>\n",
       "      <td>0.073040</td>\n",
       "      <td>0.159100</td>\n",
       "      <td>0.024688</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>1.40800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>0.91707</td>\n",
       "      <td>2.6504</td>\n",
       "      <td>0.63359</td>\n",
       "      <td>0.96002</td>\n",
       "      <td>0.99298</td>\n",
       "      <td>0.539720</td>\n",
       "      <td>0.012062</td>\n",
       "      <td>0.026481</td>\n",
       "      <td>0.101210</td>\n",
       "      <td>0.184330</td>\n",
       "      <td>0.032861</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>1.79790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92535</td>\n",
       "      <td>2.8030</td>\n",
       "      <td>0.65133</td>\n",
       "      <td>0.97600</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.484130</td>\n",
       "      <td>0.015435</td>\n",
       "      <td>0.043360</td>\n",
       "      <td>0.098946</td>\n",
       "      <td>0.183380</td>\n",
       "      <td>0.032533</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>1.80330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>0.91861</td>\n",
       "      <td>2.8114</td>\n",
       "      <td>0.64707</td>\n",
       "      <td>0.94843</td>\n",
       "      <td>0.95614</td>\n",
       "      <td>0.511860</td>\n",
       "      <td>0.045037</td>\n",
       "      <td>0.369150</td>\n",
       "      <td>0.041345</td>\n",
       "      <td>0.132970</td>\n",
       "      <td>0.017374</td>\n",
       "      <td>0.007023</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.83183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.39093</td>\n",
       "      <td>1.1025</td>\n",
       "      <td>0.73351</td>\n",
       "      <td>0.72022</td>\n",
       "      <td>0.69474</td>\n",
       "      <td>0.179540</td>\n",
       "      <td>0.076072</td>\n",
       "      <td>1.053200</td>\n",
       "      <td>0.059213</td>\n",
       "      <td>0.157470</td>\n",
       "      <td>0.024197</td>\n",
       "      <td>0.009541</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>1.20420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.47124</td>\n",
       "      <td>1.1349</td>\n",
       "      <td>0.81159</td>\n",
       "      <td>0.65915</td>\n",
       "      <td>0.47368</td>\n",
       "      <td>0.093982</td>\n",
       "      <td>0.096492</td>\n",
       "      <td>1.694500</td>\n",
       "      <td>0.098618</td>\n",
       "      <td>0.210620</td>\n",
       "      <td>0.042478</td>\n",
       "      <td>0.016848</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>1.59130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0.36870</td>\n",
       "      <td>1.0456</td>\n",
       "      <td>0.77124</td>\n",
       "      <td>0.74413</td>\n",
       "      <td>0.77368</td>\n",
       "      <td>0.222780</td>\n",
       "      <td>0.075187</td>\n",
       "      <td>1.028900</td>\n",
       "      <td>0.074488</td>\n",
       "      <td>0.179930</td>\n",
       "      <td>0.031359</td>\n",
       "      <td>0.012414</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>1.35410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.14986</td>\n",
       "      <td>1.0558</td>\n",
       "      <td>0.77733</td>\n",
       "      <td>0.73454</td>\n",
       "      <td>0.66316</td>\n",
       "      <td>0.168800</td>\n",
       "      <td>0.080410</td>\n",
       "      <td>1.176800</td>\n",
       "      <td>0.103950</td>\n",
       "      <td>0.180600</td>\n",
       "      <td>0.031585</td>\n",
       "      <td>0.008017</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>1.99750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>0.68069</td>\n",
       "      <td>1.1866</td>\n",
       "      <td>0.78745</td>\n",
       "      <td>0.73496</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>0.140290</td>\n",
       "      <td>0.072447</td>\n",
       "      <td>0.955240</td>\n",
       "      <td>0.092770</td>\n",
       "      <td>0.184510</td>\n",
       "      <td>0.032923</td>\n",
       "      <td>0.010852</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>1.85680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>0.37522</td>\n",
       "      <td>1.1417</td>\n",
       "      <td>0.81725</td>\n",
       "      <td>0.68511</td>\n",
       "      <td>0.58772</td>\n",
       "      <td>0.125230</td>\n",
       "      <td>0.091860</td>\n",
       "      <td>1.535800</td>\n",
       "      <td>0.114880</td>\n",
       "      <td>0.208610</td>\n",
       "      <td>0.041703</td>\n",
       "      <td>0.013344</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>2.02810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.28064</td>\n",
       "      <td>1.0849</td>\n",
       "      <td>0.75319</td>\n",
       "      <td>0.72152</td>\n",
       "      <td>0.71404</td>\n",
       "      <td>0.136860</td>\n",
       "      <td>0.078996</td>\n",
       "      <td>1.135800</td>\n",
       "      <td>0.141220</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.045488</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>2.40590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>0.35344</td>\n",
       "      <td>1.0329</td>\n",
       "      <td>0.78147</td>\n",
       "      <td>0.70737</td>\n",
       "      <td>0.61579</td>\n",
       "      <td>0.135030</td>\n",
       "      <td>0.089763</td>\n",
       "      <td>1.466400</td>\n",
       "      <td>0.097663</td>\n",
       "      <td>0.207030</td>\n",
       "      <td>0.041101</td>\n",
       "      <td>0.016123</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>1.69350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>0.59988</td>\n",
       "      <td>1.1427</td>\n",
       "      <td>0.71532</td>\n",
       "      <td>0.66101</td>\n",
       "      <td>0.47544</td>\n",
       "      <td>0.157470</td>\n",
       "      <td>0.113370</td>\n",
       "      <td>2.339400</td>\n",
       "      <td>0.050389</td>\n",
       "      <td>0.135850</td>\n",
       "      <td>0.018121</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>1.15260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>0.47195</td>\n",
       "      <td>1.0901</td>\n",
       "      <td>0.85409</td>\n",
       "      <td>0.53598</td>\n",
       "      <td>0.39649</td>\n",
       "      <td>0.078376</td>\n",
       "      <td>0.132270</td>\n",
       "      <td>3.184000</td>\n",
       "      <td>0.082007</td>\n",
       "      <td>0.187820</td>\n",
       "      <td>0.034074</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>1.56230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class  number  eccentricity  aspect_ratio  elongation  solidity  \\\n",
       "0        1       1       0.72694        1.4742     0.32396   0.98535   \n",
       "1        1       2       0.74173        1.5257     0.36116   0.98152   \n",
       "2        1       3       0.76722        1.5725     0.38998   0.97755   \n",
       "3        1       4       0.73797        1.4597     0.35376   0.97566   \n",
       "4        1       5       0.82301        1.7707     0.44462   0.97698   \n",
       "5        1       6       0.72997        1.4892     0.34284   0.98755   \n",
       "6        1       7       0.82063        1.7529     0.44458   0.97964   \n",
       "7        1       8       0.77982        1.6215     0.39222   0.98512   \n",
       "8        1       9       0.83089        1.8199     0.45693   0.98240   \n",
       "9        1      10       0.90631        2.3906     0.58336   0.97683   \n",
       "10       1      11       0.74590        1.4927     0.34116   0.98296   \n",
       "11       1      12       0.79606        1.6934     0.43387   0.98181   \n",
       "12       2       1       0.93361        2.7582     0.64257   0.98346   \n",
       "13       2       2       0.91186        2.4994     0.60323   0.98300   \n",
       "14       2       3       0.89063        2.2927     0.56667   0.98732   \n",
       "15       2       4       0.86755        2.0090     0.51464   0.98691   \n",
       "16       2       5       0.91852        2.5247     0.61648   0.97870   \n",
       "17       2       6       0.88795        2.2038     0.56218   0.97835   \n",
       "18       2       7       0.85121        1.9548     0.48920   0.98622   \n",
       "19       2       8       0.89084        2.2979     0.57815   0.97389   \n",
       "20       2       9       0.93062        2.8973     0.65828   0.98182   \n",
       "21       2      10       0.84113        1.8600     0.46549   0.99039   \n",
       "22       3       1       0.70273        1.2099     0.36317   0.92110   \n",
       "23       3       2       0.66307        1.2065     0.32559   0.94952   \n",
       "24       3       3       0.61289        1.0991     0.33117   0.92405   \n",
       "25       3       4       0.70668        1.2510     0.38111   0.94226   \n",
       "26       3       5       0.66889        1.1435     0.38460   0.90355   \n",
       "27       3       6       0.50139        1.0066     0.29593   0.91585   \n",
       "28       3       7       0.60803        1.0646     0.34460   0.90487   \n",
       "29       3       8       0.56599        1.0427     0.35318   0.89086   \n",
       "..     ...     ...           ...           ...         ...       ...   \n",
       "310     34       3       0.99670       11.3610     0.91400   0.91815   \n",
       "311     34       4       0.99841       16.8320     0.94116   0.85531   \n",
       "312     34       5       0.99799       15.0680     0.93667   0.88070   \n",
       "313     34       6       0.99512       10.3770     0.90564   0.92135   \n",
       "314     34       7       0.99505       10.7360     0.90851   0.92586   \n",
       "315     34       8       0.99518       10.4210     0.90385   0.96551   \n",
       "316     34       9       0.99530       10.6300     0.90598   0.88866   \n",
       "317     34      10       0.99515       10.0070     0.90328   0.91594   \n",
       "318     34      11       0.99871       19.0380     0.94834   0.85100   \n",
       "319     35       1       0.91090        2.5488     0.61060   0.97388   \n",
       "320     35       2       0.90391        2.4580     0.59770   0.98610   \n",
       "321     35       3       0.90755        2.5820     0.62394   0.96837   \n",
       "322     35       4       0.91708        2.6498     0.62919   0.98493   \n",
       "323     35       5       0.91660        2.6711     0.63330   0.98228   \n",
       "324     35       6       0.89420        2.4203     0.59323   0.98407   \n",
       "325     35       7       0.93847        3.0198     0.67312   0.98733   \n",
       "326     35       8       0.89518        2.3875     0.58100   0.98796   \n",
       "327     35       9       0.91707        2.6504     0.63359   0.96002   \n",
       "328     35      10       0.92535        2.8030     0.65133   0.97600   \n",
       "329     35      11       0.91861        2.8114     0.64707   0.94843   \n",
       "330     36       1       0.39093        1.1025     0.73351   0.72022   \n",
       "331     36       2       0.47124        1.1349     0.81159   0.65915   \n",
       "332     36       3       0.36870        1.0456     0.77124   0.74413   \n",
       "333     36       4       0.14986        1.0558     0.77733   0.73454   \n",
       "334     36       5       0.68069        1.1866     0.78745   0.73496   \n",
       "335     36       6       0.37522        1.1417     0.81725   0.68511   \n",
       "336     36       7       0.28064        1.0849     0.75319   0.72152   \n",
       "337     36       8       0.35344        1.0329     0.78147   0.70737   \n",
       "338     36       9       0.59988        1.1427     0.71532   0.66101   \n",
       "339     36      10       0.47195        1.0901     0.85409   0.53598   \n",
       "\n",
       "     convexity  iso_factor     depth  lobedness  intensity  contrast  \\\n",
       "0      1.00000    0.835920  0.004657   0.003947   0.047790  0.127950   \n",
       "1      0.99825    0.798670  0.005242   0.005002   0.024160  0.090476   \n",
       "2      1.00000    0.808120  0.007457   0.010121   0.011897  0.057445   \n",
       "3      1.00000    0.816970  0.006877   0.008607   0.015950  0.065491   \n",
       "4      1.00000    0.754930  0.007428   0.010042   0.007938  0.045339   \n",
       "5      1.00000    0.844820  0.004945   0.004451   0.010487  0.058528   \n",
       "6      0.99649    0.767700  0.005928   0.006395   0.018375  0.080587   \n",
       "7      0.99825    0.808160  0.005099   0.004731   0.024875  0.089686   \n",
       "8      1.00000    0.771060  0.006005   0.006564   0.007245  0.040616   \n",
       "9      0.99825    0.664190  0.008402   0.012848   0.007010  0.042347   \n",
       "10     1.00000    0.830880  0.005567   0.005640   0.005768  0.036511   \n",
       "11     1.00000    0.769850  0.007799   0.011071   0.013677  0.057832   \n",
       "12     1.00000    0.598510  0.005534   0.005573   0.029712  0.089889   \n",
       "13     1.00000    0.649160  0.006149   0.006882   0.018887  0.072486   \n",
       "14     1.00000    0.664270  0.002837   0.001464   0.029272  0.091328   \n",
       "15     1.00000    0.702770  0.005444   0.005394   0.030348  0.092063   \n",
       "16     1.00000    0.630370  0.005049   0.004640   0.023090  0.082029   \n",
       "17     0.99825    0.641580  0.005924   0.006387   0.032722  0.092969   \n",
       "18     1.00000    0.702670  0.003973   0.002873   0.020258  0.070841   \n",
       "19     1.00000    0.645980  0.015271   0.042443   0.028461  0.086477   \n",
       "20     1.00000    0.579500  0.006489   0.007664   0.023606  0.072237   \n",
       "21     1.00000    0.759760  0.004676   0.003979   0.062798  0.132340   \n",
       "22     0.98772    0.605550  0.023597   0.101340   0.089301  0.200880   \n",
       "23     0.99649    0.759540  0.013388   0.032621   0.021815  0.097143   \n",
       "24     0.98421    0.616610  0.025545   0.118770   0.054687  0.160600   \n",
       "25     0.99825    0.692500  0.019432   0.068724   0.031587  0.115020   \n",
       "26     0.99649    0.605710  0.028329   0.146060   0.057506  0.159310   \n",
       "27     0.99825    0.640290  0.021782   0.086347   0.054635  0.159800   \n",
       "28     0.99649    0.675170  0.031915   0.185380   0.062450  0.164110   \n",
       "29     0.99825    0.620680  0.032971   0.197850   0.026348  0.105890   \n",
       "..         ...         ...       ...        ...        ...       ...   \n",
       "310    0.93684    0.144350  0.019976   0.072629   0.020667  0.085514   \n",
       "311    0.90000    0.094537  0.035845   0.233840   0.012341  0.066682   \n",
       "312    0.95789    0.121320  0.032164   0.188280   0.011686  0.054827   \n",
       "313    0.99825    0.179410  0.016647   0.050433   0.020400  0.071662   \n",
       "314    0.99649    0.182360  0.028571   0.148560   0.017761  0.069610   \n",
       "315    0.98947    0.200510  0.007723   0.010855   0.021258  0.080385   \n",
       "316    0.95789    0.159670  0.025636   0.119610   0.014782  0.065416   \n",
       "317    0.97719    0.162440  0.033129   0.199750   0.017258  0.070646   \n",
       "318    0.90702    0.086183  0.073048   0.971170   0.007817  0.048089   \n",
       "319    0.99825    0.558180  0.019720   0.070775   0.101320  0.170220   \n",
       "320    1.00000    0.614290  0.006701   0.008173   0.089020  0.167060   \n",
       "321    0.99825    0.556740  0.031714   0.183050   0.079387  0.162130   \n",
       "322    1.00000    0.579260  0.006805   0.008429   0.082187  0.168770   \n",
       "323    1.00000    0.516190  0.017465   0.055514   0.103680  0.181000   \n",
       "324    1.00000    0.607940  0.017430   0.055294   0.101020  0.187480   \n",
       "325    1.00000    0.532340  0.007639   0.010621   0.076290  0.180170   \n",
       "326    1.00000    0.638330  0.007793   0.011052   0.073040  0.159100   \n",
       "327    0.99298    0.539720  0.012062   0.026481   0.101210  0.184330   \n",
       "328    1.00000    0.484130  0.015435   0.043360   0.098946  0.183380   \n",
       "329    0.95614    0.511860  0.045037   0.369150   0.041345  0.132970   \n",
       "330    0.69474    0.179540  0.076072   1.053200   0.059213  0.157470   \n",
       "331    0.47368    0.093982  0.096492   1.694500   0.098618  0.210620   \n",
       "332    0.77368    0.222780  0.075187   1.028900   0.074488  0.179930   \n",
       "333    0.66316    0.168800  0.080410   1.176800   0.103950  0.180600   \n",
       "334    0.60000    0.140290  0.072447   0.955240   0.092770  0.184510   \n",
       "335    0.58772    0.125230  0.091860   1.535800   0.114880  0.208610   \n",
       "336    0.71404    0.136860  0.078996   1.135800   0.141220  0.218300   \n",
       "337    0.61579    0.135030  0.089763   1.466400   0.097663  0.207030   \n",
       "338    0.47544    0.157470  0.113370   2.339400   0.050389  0.135850   \n",
       "339    0.39649    0.078376  0.132270   3.184000   0.082007  0.187820   \n",
       "\n",
       "     smoothness  third_moment  uniformity  entropy  \n",
       "0      0.016108      0.005232    0.000275  1.17560  \n",
       "1      0.008119      0.002708    0.000075  0.69659  \n",
       "2      0.003289      0.000921    0.000038  0.44348  \n",
       "3      0.004271      0.001154    0.000066  0.58785  \n",
       "4      0.002051      0.000560    0.000023  0.34214  \n",
       "5      0.003414      0.001125    0.000025  0.34068  \n",
       "6      0.006452      0.002271    0.000041  0.53904  \n",
       "7      0.007979      0.002466    0.000147  0.66975  \n",
       "8      0.001647      0.000388    0.000033  0.33696  \n",
       "9      0.001790      0.000459    0.000028  0.28082  \n",
       "10     0.001331      0.000309    0.000032  0.25026  \n",
       "11     0.003333      0.000816    0.000139  0.49751  \n",
       "12     0.008015      0.002065    0.000239  0.91499  \n",
       "13     0.005227      0.001489    0.000083  0.67811  \n",
       "14     0.008272      0.002238    0.000202  0.87177  \n",
       "15     0.008404      0.002254    0.000199  0.94545  \n",
       "16     0.006684      0.001893    0.000125  0.71713  \n",
       "17     0.008569      0.002120    0.000277  1.00800  \n",
       "18     0.004993      0.001227    0.000149  0.74174  \n",
       "19     0.007423      0.001883    0.000243  0.91307  \n",
       "20     0.005191      0.001122    0.000256  0.90513  \n",
       "21     0.017213      0.004453    0.000655  1.65300  \n",
       "22     0.038786      0.015895    0.000405  1.53710  \n",
       "23     0.009348      0.004028    0.000036  0.53410  \n",
       "24     0.025145      0.011672    0.000121  1.10760  \n",
       "25     0.013056      0.005311    0.000086  0.72247  \n",
       "26     0.024752      0.010304    0.000185  1.13650  \n",
       "27     0.024899      0.011106    0.000162  1.05110  \n",
       "28     0.026225      0.010602    0.000230  1.23070  \n",
       "29     0.011088      0.004651    0.000052  0.62671  \n",
       "..          ...           ...         ...      ...  \n",
       "310    0.007259      0.002847    0.000047  0.67925  \n",
       "311    0.004427      0.001705    0.000018  0.41828  \n",
       "312    0.002997      0.000864    0.000044  0.50576  \n",
       "313    0.005109      0.001266    0.000170  0.71514  \n",
       "314    0.004822      0.001313    0.000131  0.59218  \n",
       "315    0.006420      0.001917    0.000096  0.66405  \n",
       "316    0.004261      0.001283    0.000064  0.52178  \n",
       "317    0.004966      0.001464    0.000072  0.59946  \n",
       "318    0.002307      0.000753    0.000013  0.34029  \n",
       "319    0.028158      0.007461    0.001097  2.38470  \n",
       "320    0.027151      0.007219    0.000966  1.89370  \n",
       "321    0.025613      0.007412    0.000699  1.69510  \n",
       "322    0.027693      0.008503    0.000640  1.71570  \n",
       "323    0.031721      0.008198    0.001421  1.97300  \n",
       "324    0.033957      0.009815    0.001179  1.82750  \n",
       "325    0.031440      0.011932    0.000723  1.24340  \n",
       "326    0.024688      0.007381    0.000841  1.40800  \n",
       "327    0.032861      0.008966    0.001415  1.79790  \n",
       "328    0.032533      0.009180    0.001330  1.80330  \n",
       "329    0.017374      0.007023    0.000189  0.83183  \n",
       "330    0.024197      0.009541    0.000247  1.20420  \n",
       "331    0.042478      0.016848    0.000581  1.59130  \n",
       "332    0.031359      0.012414    0.000347  1.35410  \n",
       "333    0.031585      0.008017    0.001432  1.99750  \n",
       "334    0.032923      0.010852    0.000594  1.85680  \n",
       "335    0.041703      0.013344    0.000820  2.02810  \n",
       "336    0.045488      0.012002    0.001515  2.40590  \n",
       "337    0.041101      0.016123    0.000453  1.69350  \n",
       "338    0.018121      0.006190    0.000265  1.15260  \n",
       "339    0.034074      0.013487    0.000329  1.56230  \n",
       "\n",
       "[340 rows x 16 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaves = pd.read_csv(\"leaf/leaf.csv\")\n",
    "leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a. Randomly pick 5 samples from each class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random(num):\n",
    "    \n",
    "    train = pd.DataFrame(columns=[\"class\", \"number\", \"eccentricity\", \"aspect_ratio\", \"elongation\", \"solidity\", \"convexity\", \"iso_factor\", \"depth\", \"lobedness\", \"intensity\", \"contrast\", \"smoothness\", \"third_moment\", \"uniformity\", \"entropy\"])\n",
    "    test = pd.DataFrame(columns=[\"class\", \"number\", \"eccentricity\", \"aspect_ratio\", \"elongation\", \"solidity\", \"convexity\", \"iso_factor\", \"depth\", \"lobedness\", \"intensity\", \"contrast\", \"smoothness\", \"third_moment\", \"uniformity\", \"entropy\"])\n",
    "    \n",
    "    # There are 36 total classes\n",
    "    for x in range(1, 37):\n",
    "        # For some reason, classes 16 through 21 are missing\n",
    "        # So skip these, because the dataframe will be empty\n",
    "        if(x > 15 and x < 22):\n",
    "            continue\n",
    "        \n",
    "        # If the class number is valid, take that class and re-index starting from 0\n",
    "        leaf_class = leaves.loc[leaves['class'] == x]\n",
    "        leaf_class = leaf_class.reset_index(drop=True)\n",
    "        \n",
    "        # For each class, select num random samples\n",
    "        for i in range(0, num):\n",
    "            # Randomly select a position\n",
    "            pos = random.randrange(0, leaf_class.shape[0])\n",
    "            \n",
    "            # Record the sample \n",
    "            train = train.append(leaf_class.loc[leaf_class.index[pos]], ignore_index=True)\n",
    "            \n",
    "            # remove the sample from the leaf_class so that it will not be re-used\n",
    "            leaf_class = leaf_class[leaf_class.index != pos]\n",
    "            leaf_class = leaf_class.reset_index(drop=True)\n",
    "            \n",
    "        # After the loop ends, any leftover samples belong in the testing set\n",
    "        for i in range(0, leaf_class.shape[0]):\n",
    "            test = test.append(leaf_class.loc[leaf_class.index[i]], ignore_index=True)\n",
    "        \n",
    "    return train, test     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = select_random(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b/c. Build a KNN (k = 1) classifier using n examples from each class where n = 1, 2, 3, 4, 5, and 6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define some functions:<br/>\n",
    "<ol>\n",
    "    <li>Select n examples from the training dataset</li>\n",
    "    <li>Drop the number column from the dataset, and move the class into a new y variable</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_from_train(num):\n",
    "    subset = pd.DataFrame(columns=[\"class\", \"number\", \"eccentricity\", \"aspect_ratio\", \"elongation\", \"solidity\", \"convexity\", \"iso_factor\", \"depth\", \"lobedness\", \"intensity\", \"contrast\", \"smoothness\", \"third_moment\", \"uniformity\", \"entropy\"])\n",
    "    leaf_class = pd.DataFrame(columns=[\"class\", \"number\", \"eccentricity\", \"aspect_ratio\", \"elongation\", \"solidity\", \"convexity\", \"iso_factor\", \"depth\", \"lobedness\", \"intensity\", \"contrast\", \"smoothness\", \"third_moment\", \"uniformity\", \"entropy\"])\n",
    "    \n",
    "    # There are 36 total classes\n",
    "    for x in range (1, 37):\n",
    "        # Classes 16 through 21 missing\n",
    "        if(x > 15 and x < 22):\n",
    "            continue\n",
    "        \n",
    "        # If the class number is valid, then take that class and re-index from 0\n",
    "        leaf_class = train.loc[train['class'] == x]\n",
    "        leaf_class = leaf_class.reset_index(drop=True)\n",
    "        \n",
    "        # get num samples from each class of the train dataset\n",
    "        for i in range (0, num):\n",
    "            # Randomly select a position\n",
    "            pos = random.randrange(0, leaf_class.shape[0])\n",
    "            \n",
    "            # Record the sample\n",
    "            subset = subset.append(leaf_class.loc[leaf_class.index[pos]], ignore_index=True)\n",
    "            \n",
    "            # Remove the sample from the temp dataframe so that it will not be re-selected\n",
    "            leaf_class = leaf_class[leaf_class.index != pos]\n",
    "            leaf_class = leaf_class.reset_index(drop=True)\n",
    "        \n",
    "    # After the loop ends, train remains in-tact, and we now have num samples from train stored in subset\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops the number column and moves the class column into a y variable\n",
    "def drop_columns(df):\n",
    "    df_y = df.iloc[:, 0]\n",
    "    df_X = df.drop(columns=['class', 'number'])\n",
    "    \n",
    "    return df_X, df_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our functions defined, start with n = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_y = drop_columns(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44375"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n = 1\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "subset = select_from_train(1)\n",
    "train_X, train_y = drop_columns(subset)\n",
    "\n",
    "knn.fit(train_X, train_y)\n",
    "score_1 = knn.score(test_X, test_y)\n",
    "score_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n = 2\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "subset = select_from_train(2)\n",
    "train_X, train_y = drop_columns(subset)\n",
    "\n",
    "knn.fit(train_X, train_y)\n",
    "score_1 = knn.score(test_X, test_y)\n",
    "score_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45625"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n = 3\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "subset = select_from_train(3)\n",
    "train_X, train_y = drop_columns(subset)\n",
    "\n",
    "knn.fit(train_X, train_y)\n",
    "score_1 = knn.score(test_X, test_y)\n",
    "score_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59375"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n = 4\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "subset = select_from_train(4)\n",
    "train_X, train_y = drop_columns(subset)\n",
    "\n",
    "knn.fit(train_X, train_y)\n",
    "score_1 = knn.score(test_X, test_y)\n",
    "score_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56875"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n = 5\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "subset = select_from_train(5)\n",
    "train_X, train_y = drop_columns(subset)\n",
    "\n",
    "knn.fit(train_X, train_y)\n",
    "score_1 = knn.score(test_X, test_y)\n",
    "score_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58125"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n = 6\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "subset = select_from_train(6)\n",
    "train_X, train_y = drop_columns(subset)\n",
    "\n",
    "knn.fit(train_X, train_y)\n",
    "score_1 = knn.score(test_X, test_y)\n",
    "score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d. repeat steps (a), (b), and (c) 20 times. Compute their mean testing accuracies and the corresponding standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_and_sd(n):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = 1) # Our KNN classifier with k = 1\n",
    "    results = []  # This will store the scores of all 20 iterations\n",
    "\n",
    "    for i in range(0, 20):\n",
    "        # Randomly pick 6 examples for training\n",
    "        train, test = select_random(6)\n",
    "\n",
    "        # Randomly pick n samples from train\n",
    "        subset = select_from_train(n)\n",
    "\n",
    "        # Drop unneeded columns\n",
    "        train_X, train_y = drop_columns(subset)\n",
    "        test_X, test_y = drop_columns(test)\n",
    "\n",
    "        # Fit classifier\n",
    "        knn.fit(train_X, train_y)\n",
    "\n",
    "        # Record the score for the model\n",
    "        results.append(knn.score(test_X, test_y))\n",
    "        \n",
    "    # Calculate the mean of the 20 runs\n",
    "    # Accuracy:\n",
    "    mean_accuracy = sum(results)/20 \n",
    "    # Standard Deviation:\n",
    "    squared_diff = 0\n",
    "    for idx in range(0, 20):\n",
    "        # Subtract the testing_accuracy from the result\n",
    "        temp = results[idx] - mean_accuracy\n",
    "        # Then square\n",
    "        temp = temp * temp\n",
    "        # Store the value\n",
    "        squared_diff += temp\n",
    "    # Find the mean of the squared differences.\n",
    "    # This gives variance, so to get standard deviation, take the square root\n",
    "    sd = sqrt(squared_diff/20)\n",
    "        \n",
    "    return (mean_accuracy, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45062499999999994   0.03816596160193005\n"
     ]
    }
   ],
   "source": [
    "# n = 1\n",
    "acc_1, sd_1 = get_acc_and_sd(1)\n",
    "print(acc_1, \" \", sd_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5506249999999999   0.028634277972388274\n"
     ]
    }
   ],
   "source": [
    "# n = 2\n",
    "acc_2, sd_2 = get_acc_and_sd(2)\n",
    "print(acc_2, \" \", sd_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6359375   0.029439755752213713\n"
     ]
    }
   ],
   "source": [
    "# n = 3\n",
    "acc_3, sd_3 = get_acc_and_sd(3)\n",
    "print(acc_3, \" \", sd_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6959374999999999   0.030953278804514393\n"
     ]
    }
   ],
   "source": [
    "# n = 4\n",
    "acc_4, sd_4 = get_acc_and_sd(4)\n",
    "print(acc_4, \" \", sd_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7556250000000001   0.018843516789601673\n"
     ]
    }
   ],
   "source": [
    "# n = 5\n",
    "acc_5, sd_5 = get_acc_and_sd(5)\n",
    "print(acc_5, \" \", sd_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8159375000000001   0.017619569198763067\n"
     ]
    }
   ],
   "source": [
    "# n = 6\n",
    "acc_6, sd_6 = get_acc_and_sd(6)\n",
    "print(acc_6, \" \", sd_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e. Plot a graph of the mean accuracies (y-axis) and standard deviation (error bar for mean accuracies) against the number of training examples (x-axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining axes and points for the graph\n",
    "acc = [(acc_1 * 100), (acc_2 * 100), (acc_3 * 100), (acc_4 * 100), (acc_5 * 100), (acc_6 * 100)]\n",
    "sd = [(sd_1 * 100), (sd_2 * 100), (sd_3 * 100), (sd_4 * 100), (sd_5 * 100), (sd_6 * 100)]\n",
    "n = [1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lines\n",
    "plt.errorbar(n, acc, sd, linestyle='None', marker='^', color='darkslateblue', markeredgecolor='firebrick', markerfacecolor='deeppink', capsize=3)\n",
    "# Axes\n",
    "plt.xlabel('Number of Training Examples')\n",
    "plt.ylabel('Mean Accuracy (%)')\n",
    "# Title\n",
    "plt.title('Mean Accuracy and Standard Deviation for KNN with N Training Samples')\n",
    "# Size\n",
    "plt.rcParams[\"figure.figsize\"] = [18, 9]\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
